import cv2
import face_recognition
import time
import tkinter as tk
from tkinter import ttk

video_capture = cv2.VideoCapture(0)

print("Ð—Ð°Ð¿ÑƒÑÐº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ð»Ð¸Ñ†...")

known_face_encodings = []
known_face_names = ["Zhannur", "Abdurakhim", "Timur", "Zhuldyz", "Darkhan", "Iskander", "Damir"]
known_face_images = ["known_faces/zhannur.jpg", "known_faces/abdurakhim.jpg", "known_faces/timur.jpg", 
                      "known_faces/zhuldyz.jpg", "known_faces/darkhan.jpg", "known_faces/iskander.jpg", "known_faces/damir.jpg"]

face_counts = {name: 0 for name in known_face_names}
last_seen = {name: 0 for name in known_face_names}
unique_faces = set()
total_faces_detected = 0

for i, image_path in enumerate(known_face_images):
    image = face_recognition.load_image_file(image_path)
    encodings = face_recognition.face_encodings(image)
    if encodings:
        known_face_encodings.append(encodings[0])
        print(f"âœ“ Ð›Ð¸Ñ†Ð¾ {known_face_names[i]} Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾!")
    else:
        print(f"âš ï¸ Ð›Ð¸Ñ†Ð¾ {known_face_names[i]} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² {image_path}!")

print("Ð’ÑÐµ Ð»Ð¸Ñ†Ð° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹. ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ ÐºÐ°Ð¼ÐµÑ€Ñ‹...")

root = tk.Tk()
root.title("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð»Ð¸Ñ†")
root.geometry("500x350")

frame = ttk.Frame(root)
frame.pack(pady=10)

tree = ttk.Treeview(frame, columns=("Name", "Count"), show="headings", height=len(known_face_names))
tree.column("Name", width=150)
tree.column("Count", width=100)
tree.heading("Name", text="Ð˜Ð¼Ñ")
tree.heading("Count", text="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾")
tree.pack()

stats = {}
for name in known_face_names:
    stats[name] = tree.insert("", "end", values=(name, face_counts[name]))

# ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
metrics_frame = ttk.LabelFrame(root, text="ðŸ“Š ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸")
metrics_frame.pack(pady=10, fill="both", expand=True)

unique_faces_label = ttk.Label(metrics_frame, text="Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð»Ð¸Ñ†Ð°: 0")
unique_faces_label.pack(pady=5)

recognition_rate_label = ttk.Label(metrics_frame, text="ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ: 0%")
recognition_rate_label.pack(pady=5)

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
def update_table():
    global total_faces_detected
    if total_faces_detected > 0:
        recognition_rate = (len(unique_faces) / total_faces_detected) * 100
    else:
        recognition_rate = 0
    
    for name in known_face_names:
        tree.item(stats[name], values=(name, face_counts[name]))
    
    unique_faces_label.config(text=f"Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð»Ð¸Ñ†Ð°: {len(unique_faces)}")
    recognition_rate_label.config(text=f"ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ: {recognition_rate:.2f}%")
    
    root.after(1000, update_table)

# ÐšÐ½Ð¾Ð¿ÐºÐ° Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ
def close_app():
    video_capture.release()
    cv2.destroyAllWindows()
    root.destroy()

btn_close = tk.Button(root, text="Ð—Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ", command=close_app, font=("Arial", 12), bg="red", fg="white")
btn_close.pack(pady=10)

update_table()

# ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð²Ð¸Ð´ÐµÐ¾
while True:
    ret, frame = video_capture.read()
    if not ret:
        print("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ðµ ÐºÐ°Ð´Ñ€Ð° Ñ ÐºÐ°Ð¼ÐµÑ€Ñ‹!")
        break
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)
    
    total_faces_detected += len(face_encodings)
    current_time = time.time()
    
    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
        name = "Unknown"
        
        if True in matches:
            first_match_index = matches.index(True)
            name = known_face_names[first_match_index]
            unique_faces.add(name)
            
            if current_time - last_seen[name] > 2:
                face_counts[name] += 1
                last_seen[name] = current_time
        
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    
    cv2.imshow('Face Recognition', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video_capture.release()
cv2.destroyAllWindows()
root.mainloop()
