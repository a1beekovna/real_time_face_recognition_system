import cv2
import face_recognition
import time
import tkinter as tk
from tkinter import ttk

# –ó–∞–ø—É—Å–∫ –≤–µ–±-–∫–∞–º–µ—Ä—ã
video_capture = cv2.VideoCapture(0)

print("–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü...")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—Ü
known_face_encodings = []
known_face_names = ["Zhannur", "Abdurakhim", "Timur", "Zhuldyz", "Darkhan", "Iskander", "Damir"]
known_face_images = ["known_faces/zhannur.jpg", "known_faces/abdurakhim.jpg", "known_faces/timur.jpg", 
                      "known_faces/zhuldyz.jpg", "known_faces/darkhan.jpg", "known_faces/iskander.jpg", "known_faces/damir.jpg"]

# –°—á–µ—Ç—á–∏–∫ –ø–æ—è–≤–ª–µ–Ω–∏–π –ª–∏—Ü
face_counts = {name: 0 for name in known_face_names}
# –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ—è–≤–ª–µ–Ω–∏—è –ª–∏—Ü–∞
last_seen = {name: 0 for name in known_face_names}

for i, image_path in enumerate(known_face_images):
    image = face_recognition.load_image_file(image_path)
    encodings = face_recognition.face_encodings(image)
    if encodings:
        known_face_encodings.append(encodings[0])
        print(f"‚úì –õ–∏—Ü–æ {known_face_names[i]} –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")
    else:
        print(f"‚ö†Ô∏è –õ–∏—Ü–æ {known_face_names[i]} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ {image_path}!")

print("–í—Å–µ –ª–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞–±–æ—Ç—É –∫–∞–º–µ—Ä—ã...")

# üé® –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–æ Tkinter
root = tk.Tk()
root.title("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ª–∏—Ü")
root.geometry("400x300")

# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
frame = ttk.Frame(root)
frame.pack(pady=10)

tree = ttk.Treeview(frame, columns=("Name", "Count"), show="headings", height=len(known_face_names))
tree.column("Name", width=150)
tree.column("Count", width=100)
tree.heading("Name", text="–ò–º—è")
tree.heading("Count", text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
tree.pack()

# –ó–∞–ø–æ–ª–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—É
stats = {}
for name in known_face_names:
    stats[name] = tree.insert("", "end", values=(name, face_counts[name]))

# –§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
def update_table():
    for name in known_face_names:
        tree.item(stats[name], values=(name, face_counts[name]))
    root.after(1000, update_table)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã
def close_app():
    video_capture.release()
    cv2.destroyAllWindows()
    root.destroy()

btn_close = tk.Button(root, text="–ó–∞–∫—Ä—ã—Ç—å", command=close_app, font=("Arial", 12), bg="red", fg="white")
btn_close.pack(pady=10)

update_table()  # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

# üé• –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
while True:
    ret, frame = video_capture.read()
    if not ret:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞—Ö–≤–∞—Ç–µ –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã!")
        break
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

    current_time = time.time()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è

    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
        name = "Unknown"

        if True in matches:
            first_match_index = matches.index(True)
            name = known_face_names[first_match_index]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ 2 —Å–µ–∫—É–Ω–¥—ã —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è
            if current_time - last_seen[name] > 2:
                face_counts[name] += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
                last_seen[name] = current_time  # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–º–∫–∏ –∏ –∏–º–µ–Ω–∏
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # –í—ã–≤–æ–¥ –≤–∏–¥–µ–æ
    cv2.imshow('Face Recognition', frame)

    # –í—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ –Ω–∞–∂–∞—Ç–∏—é "q"
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ GUI
print("\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
for name, count in face_counts.items():
    print(f"{name}: {count} —Ä–∞–∑(–∞)")

# –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ OpenCV
video_capture.release()
cv2.destroyAllWindows()

# –ó–∞–ø—É—Å–∫–∞–µ–º Tkinter GUI
root.mainloop()
